{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alice_new.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyas1/Alice_in_wonderland_text_generator/blob/master/Alice_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JyKGP1jkzi4F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bq92_PzLlU6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('alice.txt', 'r') as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7PMaiQnndQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ae46381-dae5-440a-d1d6-053f767bbec7"
      },
      "cell_type": "code",
      "source": [
        "text[:50]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                     Down the Rabbit-Hole\\n\\n  Alice'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "-cSFLvWntJvw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "text = text.lower()\n",
        "text = ''.join([c for c in text if c not in punctuation])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1PREMSYsHBV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words=text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3g1YGPhMsKBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "b55cc82e-7402-4af7-a7d5-e897c15f8ff9"
      },
      "cell_type": "code",
      "source": [
        "words[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['down',\n",
              " 'the',\n",
              " 'rabbithole',\n",
              " 'alice',\n",
              " 'was',\n",
              " 'beginning',\n",
              " 'to',\n",
              " 'get',\n",
              " 'very',\n",
              " 'tired']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "b5EzUtcttxkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Unique words"
      ]
    },
    {
      "metadata": {
        "id": "qAfdOqtus_1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c32f7594-49be-4a6f-f1b0-baa5a7dcc2eb"
      },
      "cell_type": "code",
      "source": [
        "len(set(words))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "a_15bt4yt2L-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "total words"
      ]
    },
    {
      "metadata": {
        "id": "ju8UUa_Yp70K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "447b9ee5-434d-4971-92eb-abb349d7c790"
      },
      "cell_type": "code",
      "source": [
        "len(words)\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "LZtWdPUbtuV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length=51\n",
        "sequences=list()\n",
        "for i in range(length,len(words)):\n",
        "  seq=words[i-length:i]\n",
        "  line=' '.join(seq)\n",
        "  sequences.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2_48xhNx_vv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11fa6d54-2349-4258-ae07-dc0b6663be35"
      },
      "cell_type": "code",
      "source": [
        "print('total sequences:- %d'%(len(sequences)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total sequences:- 26318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BeBInvH9yOnw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                   lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(sequences)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qvj_LZ4JyaqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "line_sequence=tokenizer.texts_to_sequences(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WgPSnajUzMA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1785
        },
        "outputId": "c0d25719-e664-4f26-fb80-42643305901f"
      },
      "cell_type": "code",
      "source": [
        "line_sequence[:2]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[37,\n",
              "  1,\n",
              "  1055,\n",
              "  10,\n",
              "  13,\n",
              "  298,\n",
              "  3,\n",
              "  101,\n",
              "  27,\n",
              "  525,\n",
              "  7,\n",
              "  378,\n",
              "  79,\n",
              "  16,\n",
              "  521,\n",
              "  18,\n",
              "  1,\n",
              "  1467,\n",
              "  2,\n",
              "  7,\n",
              "  377,\n",
              "  130,\n",
              "  3,\n",
              "  52,\n",
              "  138,\n",
              "  56,\n",
              "  679,\n",
              "  5,\n",
              "  21,\n",
              "  1054,\n",
              "  63,\n",
              "  1,\n",
              "  523,\n",
              "  16,\n",
              "  521,\n",
              "  13,\n",
              "  1053,\n",
              "  22,\n",
              "  6,\n",
              "  21,\n",
              "  44,\n",
              "  822,\n",
              "  56,\n",
              "  2728,\n",
              "  11,\n",
              "  6,\n",
              "  2,\n",
              "  28,\n",
              "  35,\n",
              "  1,\n",
              "  209],\n",
              " [1,\n",
              "  1055,\n",
              "  10,\n",
              "  13,\n",
              "  298,\n",
              "  3,\n",
              "  101,\n",
              "  27,\n",
              "  525,\n",
              "  7,\n",
              "  378,\n",
              "  79,\n",
              "  16,\n",
              "  521,\n",
              "  18,\n",
              "  1,\n",
              "  1467,\n",
              "  2,\n",
              "  7,\n",
              "  377,\n",
              "  130,\n",
              "  3,\n",
              "  52,\n",
              "  138,\n",
              "  56,\n",
              "  679,\n",
              "  5,\n",
              "  21,\n",
              "  1054,\n",
              "  63,\n",
              "  1,\n",
              "  523,\n",
              "  16,\n",
              "  521,\n",
              "  13,\n",
              "  1053,\n",
              "  22,\n",
              "  6,\n",
              "  21,\n",
              "  44,\n",
              "  822,\n",
              "  56,\n",
              "  2728,\n",
              "  11,\n",
              "  6,\n",
              "  2,\n",
              "  28,\n",
              "  35,\n",
              "  1,\n",
              "  209,\n",
              "  7]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "tJ-Xm61UzQfU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSfaL_t4zZL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6980857-b8a3-4869-9214-2f9ec01dfe05"
      },
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "otEN9PwszbH8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "line_sequence=np.array(line_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6zw-JXXfzxmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y=line_sequence[:,:-1],line_sequence[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XOrqMeJ20GEx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y=to_categorical(y,num_classes=vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5HAeqmUf1c1x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq_len=x.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81EqauHH1xEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6530849a-34eb-44d6-97d4-20dc97cfd2b2"
      },
      "cell_type": "code",
      "source": [
        "seq_len"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "u1x2gOnb1yKb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import CuDNNLSTM,Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hx--dB-92Eqd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCXxie_l2QIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "eac988d0-2649-43f9-ba73-40b09f45174a"
      },
      "cell_type": "code",
      "source": [
        "model.add(Embedding(vocab_size,55,input_length =seq_len))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MgH2-Xue3k4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d0de1811-9608-4975-b68d-5b3f98150d19"
      },
      "cell_type": "code",
      "source": [
        "model.add(CuDNNLSTM(128,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(CuDNNLSTM(128))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SBiIM0Fy4VZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "9c28fe18-6c4e-4d52-f1dc-39393c4a3658"
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(vocab_size,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 55)            150370    \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)       (None, 50, 128)           94720     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 128)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               132096    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2734)              352686    \n",
            "=================================================================\n",
            "Total params: 729,872\n",
            "Trainable params: 729,872\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eorNBdRl4l3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19797
        },
        "outputId": "7f511185-42ec-4993-cf11-a64acb120f76"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x,y, batch_size =128, nb_epoch = 1000)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1000\n",
            "26318/26318 [==============================] - 9s 357us/sample - loss: 6.3469 - acc: 0.0608\n",
            "Epoch 2/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 6.0092 - acc: 0.0618\n",
            "Epoch 3/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.8850 - acc: 0.0656\n",
            "Epoch 4/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 5.7541 - acc: 0.0699\n",
            "Epoch 5/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 5.6536 - acc: 0.0744\n",
            "Epoch 6/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 5.5799 - acc: 0.0763\n",
            "Epoch 7/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.5150 - acc: 0.0786\n",
            "Epoch 8/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.4577 - acc: 0.0803\n",
            "Epoch 9/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 5.4065 - acc: 0.0830\n",
            "Epoch 10/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.3626 - acc: 0.0855\n",
            "Epoch 11/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 5.3173 - acc: 0.0883\n",
            "Epoch 12/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 5.2694 - acc: 0.0881\n",
            "Epoch 13/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 5.5240 - acc: 0.0777\n",
            "Epoch 14/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.4123 - acc: 0.0840\n",
            "Epoch 15/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.2511 - acc: 0.0914\n",
            "Epoch 16/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 5.1611 - acc: 0.0997\n",
            "Epoch 17/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 5.0982 - acc: 0.1059\n",
            "Epoch 18/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.0492 - acc: 0.1102\n",
            "Epoch 19/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.9972 - acc: 0.1127\n",
            "Epoch 20/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 5.0136 - acc: 0.1154\n",
            "Epoch 21/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.9541 - acc: 0.1171\n",
            "Epoch 22/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 4.8893 - acc: 0.1219\n",
            "Epoch 23/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.8356 - acc: 0.1235\n",
            "Epoch 24/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.7878 - acc: 0.1282\n",
            "Epoch 25/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.7544 - acc: 0.1308\n",
            "Epoch 26/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 4.7071 - acc: 0.1341\n",
            "Epoch 27/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.6569 - acc: 0.1382\n",
            "Epoch 28/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.6152 - acc: 0.1391\n",
            "Epoch 29/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.5936 - acc: 0.1413\n",
            "Epoch 30/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.5555 - acc: 0.1413\n",
            "Epoch 31/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.5166 - acc: 0.1475\n",
            "Epoch 32/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.5246 - acc: 0.1453\n",
            "Epoch 33/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.5397 - acc: 0.1487\n",
            "Epoch 34/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.4703 - acc: 0.1508\n",
            "Epoch 35/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.4111 - acc: 0.1545\n",
            "Epoch 36/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.3791 - acc: 0.1570\n",
            "Epoch 37/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.3659 - acc: 0.1580\n",
            "Epoch 38/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.2910 - acc: 0.1624\n",
            "Epoch 39/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.2627 - acc: 0.1634\n",
            "Epoch 40/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.2607 - acc: 0.1652\n",
            "Epoch 41/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 4.3055 - acc: 0.1644\n",
            "Epoch 42/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 4.2293 - acc: 0.1696\n",
            "Epoch 43/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.1439 - acc: 0.1744\n",
            "Epoch 44/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.1097 - acc: 0.1759\n",
            "Epoch 45/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.1268 - acc: 0.1728\n",
            "Epoch 46/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.0764 - acc: 0.1765\n",
            "Epoch 47/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.0465 - acc: 0.1793\n",
            "Epoch 48/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 4.0180 - acc: 0.1811\n",
            "Epoch 49/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.1264 - acc: 0.1733\n",
            "Epoch 50/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.2255 - acc: 0.1682\n",
            "Epoch 51/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.4356 - acc: 0.1571\n",
            "Epoch 52/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.3663 - acc: 0.1600\n",
            "Epoch 53/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.3255 - acc: 0.1627\n",
            "Epoch 54/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.2797 - acc: 0.1667\n",
            "Epoch 55/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.2465 - acc: 0.1679\n",
            "Epoch 56/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.2127 - acc: 0.1680\n",
            "Epoch 57/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.1839 - acc: 0.1715\n",
            "Epoch 58/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.1603 - acc: 0.1720\n",
            "Epoch 59/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 4.1272 - acc: 0.1759\n",
            "Epoch 60/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 4.0964 - acc: 0.1755\n",
            "Epoch 61/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 4.0667 - acc: 0.1799\n",
            "Epoch 62/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.0448 - acc: 0.1815\n",
            "Epoch 63/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 4.0230 - acc: 0.1831\n",
            "Epoch 64/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.9882 - acc: 0.1855\n",
            "Epoch 65/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.9667 - acc: 0.1877\n",
            "Epoch 66/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.9423 - acc: 0.1890\n",
            "Epoch 67/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.9102 - acc: 0.1946\n",
            "Epoch 68/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.8896 - acc: 0.1945\n",
            "Epoch 69/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 3.8688 - acc: 0.1980\n",
            "Epoch 70/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.8426 - acc: 0.1983\n",
            "Epoch 71/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.8190 - acc: 0.2032\n",
            "Epoch 72/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.7997 - acc: 0.2045\n",
            "Epoch 73/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.7703 - acc: 0.2081\n",
            "Epoch 74/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.7448 - acc: 0.2114\n",
            "Epoch 75/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.7200 - acc: 0.2108\n",
            "Epoch 76/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.7020 - acc: 0.2154\n",
            "Epoch 77/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.6773 - acc: 0.2164\n",
            "Epoch 78/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.6524 - acc: 0.2236\n",
            "Epoch 79/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.6317 - acc: 0.2221\n",
            "Epoch 80/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.6032 - acc: 0.2273\n",
            "Epoch 81/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.5896 - acc: 0.2284\n",
            "Epoch 82/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.5652 - acc: 0.2308\n",
            "Epoch 83/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.5420 - acc: 0.2339\n",
            "Epoch 84/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.5255 - acc: 0.2366\n",
            "Epoch 85/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.5083 - acc: 0.2377\n",
            "Epoch 86/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.4846 - acc: 0.2436\n",
            "Epoch 87/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.4700 - acc: 0.2408\n",
            "Epoch 88/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.4533 - acc: 0.2446\n",
            "Epoch 89/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.4289 - acc: 0.2516\n",
            "Epoch 90/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 3.4015 - acc: 0.2500\n",
            "Epoch 91/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.3767 - acc: 0.2555\n",
            "Epoch 92/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.3688 - acc: 0.2566\n",
            "Epoch 93/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.3409 - acc: 0.2609\n",
            "Epoch 94/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.3303 - acc: 0.2626\n",
            "Epoch 95/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.3085 - acc: 0.2647\n",
            "Epoch 96/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.2869 - acc: 0.2664\n",
            "Epoch 97/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.2792 - acc: 0.2672\n",
            "Epoch 98/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.2640 - acc: 0.2721\n",
            "Epoch 99/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.2365 - acc: 0.2721\n",
            "Epoch 100/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.2139 - acc: 0.2769\n",
            "Epoch 101/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.2141 - acc: 0.2774\n",
            "Epoch 102/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.1889 - acc: 0.2851\n",
            "Epoch 103/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.1685 - acc: 0.2860\n",
            "Epoch 104/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.1512 - acc: 0.2888\n",
            "Epoch 105/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.1291 - acc: 0.2913\n",
            "Epoch 106/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.1226 - acc: 0.2919\n",
            "Epoch 107/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.0972 - acc: 0.2941\n",
            "Epoch 108/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 3.0859 - acc: 0.3002\n",
            "Epoch 109/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 3.0722 - acc: 0.3001\n",
            "Epoch 110/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 3.0602 - acc: 0.3036\n",
            "Epoch 111/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 3.0394 - acc: 0.3075\n",
            "Epoch 112/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.0216 - acc: 0.3105\n",
            "Epoch 113/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 3.0104 - acc: 0.3123\n",
            "Epoch 114/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.9937 - acc: 0.3156\n",
            "Epoch 115/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.9818 - acc: 0.3150\n",
            "Epoch 116/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.9695 - acc: 0.3167\n",
            "Epoch 117/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.9520 - acc: 0.3165\n",
            "Epoch 118/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.9402 - acc: 0.3234\n",
            "Epoch 119/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.9233 - acc: 0.3263\n",
            "Epoch 120/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.9108 - acc: 0.3236\n",
            "Epoch 121/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.9014 - acc: 0.3292\n",
            "Epoch 122/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.8848 - acc: 0.3367\n",
            "Epoch 123/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 2.8721 - acc: 0.3313\n",
            "Epoch 124/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.8584 - acc: 0.3353\n",
            "Epoch 125/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.8373 - acc: 0.3399\n",
            "Epoch 126/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.8334 - acc: 0.3420\n",
            "Epoch 127/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.8060 - acc: 0.3471\n",
            "Epoch 128/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.7967 - acc: 0.3471\n",
            "Epoch 129/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.7840 - acc: 0.3456\n",
            "Epoch 130/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.7833 - acc: 0.3523\n",
            "Epoch 131/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.7643 - acc: 0.3560\n",
            "Epoch 132/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.7469 - acc: 0.3567\n",
            "Epoch 133/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.7409 - acc: 0.3554\n",
            "Epoch 134/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.7309 - acc: 0.3568\n",
            "Epoch 135/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.7207 - acc: 0.3583\n",
            "Epoch 136/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.6938 - acc: 0.3627\n",
            "Epoch 137/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.6825 - acc: 0.3672\n",
            "Epoch 138/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 2.6787 - acc: 0.3661\n",
            "Epoch 139/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.6630 - acc: 0.3723\n",
            "Epoch 140/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.6548 - acc: 0.3674\n",
            "Epoch 141/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.6333 - acc: 0.3763\n",
            "Epoch 142/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.6221 - acc: 0.3791\n",
            "Epoch 143/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.6155 - acc: 0.3791\n",
            "Epoch 144/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.6125 - acc: 0.3783\n",
            "Epoch 145/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5951 - acc: 0.3831\n",
            "Epoch 146/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5817 - acc: 0.3836\n",
            "Epoch 147/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5668 - acc: 0.3863\n",
            "Epoch 148/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5529 - acc: 0.3898\n",
            "Epoch 149/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5457 - acc: 0.3892\n",
            "Epoch 150/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5395 - acc: 0.3896\n",
            "Epoch 151/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5208 - acc: 0.3963\n",
            "Epoch 152/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.5217 - acc: 0.3924\n",
            "Epoch 153/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.5033 - acc: 0.3980\n",
            "Epoch 154/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.4939 - acc: 0.3992\n",
            "Epoch 155/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.4824 - acc: 0.4016\n",
            "Epoch 156/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.4627 - acc: 0.4052\n",
            "Epoch 157/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.4654 - acc: 0.4060\n",
            "Epoch 158/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 2.4484 - acc: 0.4063\n",
            "Epoch 159/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 2.4305 - acc: 0.4101\n",
            "Epoch 160/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.4344 - acc: 0.4070\n",
            "Epoch 161/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.4315 - acc: 0.4112\n",
            "Epoch 162/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.4171 - acc: 0.4124\n",
            "Epoch 163/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.3920 - acc: 0.4213\n",
            "Epoch 164/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.3840 - acc: 0.4197\n",
            "Epoch 165/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.3702 - acc: 0.4246\n",
            "Epoch 166/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.3678 - acc: 0.4260\n",
            "Epoch 167/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.3587 - acc: 0.4247\n",
            "Epoch 168/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.3602 - acc: 0.4251\n",
            "Epoch 169/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.3402 - acc: 0.4280\n",
            "Epoch 170/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.3347 - acc: 0.4254\n",
            "Epoch 171/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.3186 - acc: 0.4329\n",
            "Epoch 172/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.3192 - acc: 0.4309\n",
            "Epoch 173/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.3023 - acc: 0.4314\n",
            "Epoch 174/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2916 - acc: 0.4367\n",
            "Epoch 175/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2911 - acc: 0.4359\n",
            "Epoch 176/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2807 - acc: 0.4368\n",
            "Epoch 177/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2698 - acc: 0.4411\n",
            "Epoch 178/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2575 - acc: 0.4448\n",
            "Epoch 179/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2466 - acc: 0.4465\n",
            "Epoch 180/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.2436 - acc: 0.4467\n",
            "Epoch 181/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.2357 - acc: 0.4492\n",
            "Epoch 182/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.2274 - acc: 0.4489\n",
            "Epoch 183/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2127 - acc: 0.4505\n",
            "Epoch 184/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.2057 - acc: 0.4551\n",
            "Epoch 185/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 2.1938 - acc: 0.4569\n",
            "Epoch 186/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 2.1953 - acc: 0.4580\n",
            "Epoch 187/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 2.1845 - acc: 0.4622\n",
            "Epoch 188/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.1726 - acc: 0.4615\n",
            "Epoch 189/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.1689 - acc: 0.4629\n",
            "Epoch 190/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.1557 - acc: 0.4652\n",
            "Epoch 191/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.1477 - acc: 0.4651\n",
            "Epoch 192/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.1370 - acc: 0.4666\n",
            "Epoch 193/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.1288 - acc: 0.4677\n",
            "Epoch 194/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.1087 - acc: 0.4734\n",
            "Epoch 195/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.1113 - acc: 0.4698\n",
            "Epoch 196/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.1006 - acc: 0.4731\n",
            "Epoch 197/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.1093 - acc: 0.4694\n",
            "Epoch 198/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.0956 - acc: 0.4732\n",
            "Epoch 199/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.0889 - acc: 0.4799\n",
            "Epoch 200/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.0683 - acc: 0.4823\n",
            "Epoch 201/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.0770 - acc: 0.4793\n",
            "Epoch 202/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.0516 - acc: 0.4843\n",
            "Epoch 203/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 2.0591 - acc: 0.4851\n",
            "Epoch 204/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 2.0419 - acc: 0.4887\n",
            "Epoch 205/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.0417 - acc: 0.4885\n",
            "Epoch 206/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.0370 - acc: 0.4848\n",
            "Epoch 207/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 2.0173 - acc: 0.4883\n",
            "Epoch 208/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 2.0118 - acc: 0.4947\n",
            "Epoch 209/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.0203 - acc: 0.4899\n",
            "Epoch 210/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 2.0000 - acc: 0.4952\n",
            "Epoch 211/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.9977 - acc: 0.4947\n",
            "Epoch 212/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.9914 - acc: 0.4946\n",
            "Epoch 213/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.9840 - acc: 0.4940\n",
            "Epoch 214/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.9763 - acc: 0.4981\n",
            "Epoch 215/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.9806 - acc: 0.4967\n",
            "Epoch 216/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.9559 - acc: 0.5031\n",
            "Epoch 217/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.9564 - acc: 0.5017\n",
            "Epoch 218/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.9470 - acc: 0.5024\n",
            "Epoch 219/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.9412 - acc: 0.5047\n",
            "Epoch 220/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.9286 - acc: 0.5084\n",
            "Epoch 221/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.9305 - acc: 0.5068\n",
            "Epoch 222/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.9183 - acc: 0.5131\n",
            "Epoch 223/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.9176 - acc: 0.5090\n",
            "Epoch 224/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.9150 - acc: 0.5083\n",
            "Epoch 225/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.9048 - acc: 0.5123\n",
            "Epoch 226/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.9021 - acc: 0.5131\n",
            "Epoch 227/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.8877 - acc: 0.5151\n",
            "Epoch 228/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.8752 - acc: 0.5197\n",
            "Epoch 229/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.8830 - acc: 0.5168\n",
            "Epoch 230/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.8635 - acc: 0.5183\n",
            "Epoch 231/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.8654 - acc: 0.5250\n",
            "Epoch 232/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.8633 - acc: 0.5202\n",
            "Epoch 233/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.8513 - acc: 0.5245\n",
            "Epoch 234/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.8418 - acc: 0.5257\n",
            "Epoch 235/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.8445 - acc: 0.5231\n",
            "Epoch 236/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.8441 - acc: 0.5226\n",
            "Epoch 237/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.8234 - acc: 0.5260\n",
            "Epoch 238/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.8235 - acc: 0.5348\n",
            "Epoch 239/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.8098 - acc: 0.5347\n",
            "Epoch 240/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.8072 - acc: 0.5282\n",
            "Epoch 241/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.8102 - acc: 0.5298\n",
            "Epoch 242/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.7929 - acc: 0.5359\n",
            "Epoch 243/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7924 - acc: 0.5335\n",
            "Epoch 244/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.7732 - acc: 0.5407\n",
            "Epoch 245/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.7822 - acc: 0.5341\n",
            "Epoch 246/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.7772 - acc: 0.5382\n",
            "Epoch 247/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7638 - acc: 0.5417\n",
            "Epoch 248/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.7569 - acc: 0.5387\n",
            "Epoch 249/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7600 - acc: 0.5379\n",
            "Epoch 250/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7464 - acc: 0.5459\n",
            "Epoch 251/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.7450 - acc: 0.5463\n",
            "Epoch 252/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7426 - acc: 0.5448\n",
            "Epoch 253/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7365 - acc: 0.5485\n",
            "Epoch 254/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7363 - acc: 0.5464\n",
            "Epoch 255/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.7326 - acc: 0.5442\n",
            "Epoch 256/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 1.7265 - acc: 0.5498\n",
            "Epoch 257/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 1.7242 - acc: 0.5497\n",
            "Epoch 258/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.7117 - acc: 0.5532\n",
            "Epoch 259/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.6964 - acc: 0.5535\n",
            "Epoch 260/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.6910 - acc: 0.5589\n",
            "Epoch 261/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.6900 - acc: 0.5552\n",
            "Epoch 262/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6841 - acc: 0.5595\n",
            "Epoch 263/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.6834 - acc: 0.5596\n",
            "Epoch 264/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.6876 - acc: 0.5559\n",
            "Epoch 265/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.6772 - acc: 0.5603\n",
            "Epoch 266/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.6604 - acc: 0.5645\n",
            "Epoch 267/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6661 - acc: 0.5598\n",
            "Epoch 268/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.6689 - acc: 0.5627\n",
            "Epoch 269/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6606 - acc: 0.5640\n",
            "Epoch 270/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.6467 - acc: 0.5681\n",
            "Epoch 271/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6501 - acc: 0.5630\n",
            "Epoch 272/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6404 - acc: 0.5676\n",
            "Epoch 273/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6213 - acc: 0.5728\n",
            "Epoch 274/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.6335 - acc: 0.5692\n",
            "Epoch 275/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.6177 - acc: 0.5723\n",
            "Epoch 276/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6156 - acc: 0.5725\n",
            "Epoch 277/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.6336 - acc: 0.5660\n",
            "Epoch 278/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6141 - acc: 0.5725\n",
            "Epoch 279/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.6163 - acc: 0.5715\n",
            "Epoch 280/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.6051 - acc: 0.5755\n",
            "Epoch 281/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.5983 - acc: 0.5782\n",
            "Epoch 282/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.5876 - acc: 0.5793\n",
            "Epoch 283/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 1.5999 - acc: 0.5774\n",
            "Epoch 284/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5775 - acc: 0.5797\n",
            "Epoch 285/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5701 - acc: 0.5823\n",
            "Epoch 286/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5698 - acc: 0.5834\n",
            "Epoch 287/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5838 - acc: 0.5765\n",
            "Epoch 288/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5722 - acc: 0.5823\n",
            "Epoch 289/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5583 - acc: 0.5862\n",
            "Epoch 290/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5558 - acc: 0.5869\n",
            "Epoch 291/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5549 - acc: 0.5863\n",
            "Epoch 292/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.5501 - acc: 0.5888\n",
            "Epoch 293/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5485 - acc: 0.5852\n",
            "Epoch 294/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.5454 - acc: 0.5896\n",
            "Epoch 295/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.5285 - acc: 0.5935\n",
            "Epoch 296/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.5288 - acc: 0.5894\n",
            "Epoch 297/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5140 - acc: 0.5931\n",
            "Epoch 298/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5060 - acc: 0.5945\n",
            "Epoch 299/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5130 - acc: 0.5958\n",
            "Epoch 300/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5130 - acc: 0.5947\n",
            "Epoch 301/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.5147 - acc: 0.5947\n",
            "Epoch 302/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5070 - acc: 0.5958\n",
            "Epoch 303/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4910 - acc: 0.5969\n",
            "Epoch 304/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.5013 - acc: 0.5953\n",
            "Epoch 305/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 1.4885 - acc: 0.6011\n",
            "Epoch 306/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 1.4845 - acc: 0.5992\n",
            "Epoch 307/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4843 - acc: 0.5987\n",
            "Epoch 308/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4751 - acc: 0.6047\n",
            "Epoch 309/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4756 - acc: 0.6039\n",
            "Epoch 310/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4718 - acc: 0.6075\n",
            "Epoch 311/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4679 - acc: 0.6056\n",
            "Epoch 312/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4724 - acc: 0.6059\n",
            "Epoch 313/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4691 - acc: 0.6052\n",
            "Epoch 314/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4543 - acc: 0.6083\n",
            "Epoch 315/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4553 - acc: 0.6092\n",
            "Epoch 316/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4539 - acc: 0.6063\n",
            "Epoch 317/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4446 - acc: 0.6092\n",
            "Epoch 318/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4539 - acc: 0.6074\n",
            "Epoch 319/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4501 - acc: 0.6041\n",
            "Epoch 320/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4361 - acc: 0.6139\n",
            "Epoch 321/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4332 - acc: 0.6126\n",
            "Epoch 322/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4215 - acc: 0.6146\n",
            "Epoch 323/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4197 - acc: 0.6131\n",
            "Epoch 324/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4216 - acc: 0.6145\n",
            "Epoch 325/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4185 - acc: 0.6158\n",
            "Epoch 326/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4180 - acc: 0.6139\n",
            "Epoch 327/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.4104 - acc: 0.6127\n",
            "Epoch 328/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4111 - acc: 0.6206\n",
            "Epoch 329/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4184 - acc: 0.6130\n",
            "Epoch 330/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.4132 - acc: 0.6183\n",
            "Epoch 331/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 1.4008 - acc: 0.6182\n",
            "Epoch 332/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3945 - acc: 0.6227\n",
            "Epoch 333/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3933 - acc: 0.6188\n",
            "Epoch 334/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3897 - acc: 0.6201\n",
            "Epoch 335/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3917 - acc: 0.6207\n",
            "Epoch 336/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3997 - acc: 0.6208\n",
            "Epoch 337/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.3936 - acc: 0.6200\n",
            "Epoch 338/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3765 - acc: 0.6237\n",
            "Epoch 339/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3714 - acc: 0.6246\n",
            "Epoch 340/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3781 - acc: 0.6276\n",
            "Epoch 341/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3604 - acc: 0.6306\n",
            "Epoch 342/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3561 - acc: 0.6278\n",
            "Epoch 343/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3523 - acc: 0.6296\n",
            "Epoch 344/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3409 - acc: 0.6322\n",
            "Epoch 345/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3453 - acc: 0.6334\n",
            "Epoch 346/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3376 - acc: 0.6318\n",
            "Epoch 347/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.3511 - acc: 0.6331\n",
            "Epoch 348/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.3516 - acc: 0.6306\n",
            "Epoch 349/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3377 - acc: 0.6318\n",
            "Epoch 350/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3408 - acc: 0.6343\n",
            "Epoch 351/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3262 - acc: 0.6352\n",
            "Epoch 352/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3221 - acc: 0.6363\n",
            "Epoch 353/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3306 - acc: 0.6332\n",
            "Epoch 354/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 1.3215 - acc: 0.6385\n",
            "Epoch 355/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 1.3207 - acc: 0.6375\n",
            "Epoch 356/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3330 - acc: 0.6336\n",
            "Epoch 357/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3200 - acc: 0.6354\n",
            "Epoch 358/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.3053 - acc: 0.6406\n",
            "Epoch 359/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3148 - acc: 0.6375\n",
            "Epoch 360/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3087 - acc: 0.6389\n",
            "Epoch 361/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3102 - acc: 0.6366\n",
            "Epoch 362/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.3043 - acc: 0.6434\n",
            "Epoch 363/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.3044 - acc: 0.6404\n",
            "Epoch 364/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.2946 - acc: 0.6446\n",
            "Epoch 365/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2933 - acc: 0.6422\n",
            "Epoch 366/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2994 - acc: 0.6406\n",
            "Epoch 367/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2894 - acc: 0.6395\n",
            "Epoch 368/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2765 - acc: 0.6479\n",
            "Epoch 369/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2740 - acc: 0.6462\n",
            "Epoch 370/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2734 - acc: 0.6461\n",
            "Epoch 371/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2755 - acc: 0.6469\n",
            "Epoch 372/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2623 - acc: 0.6556\n",
            "Epoch 373/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2657 - acc: 0.6475\n",
            "Epoch 374/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2739 - acc: 0.6500\n",
            "Epoch 375/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2651 - acc: 0.6453\n",
            "Epoch 376/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2474 - acc: 0.6552\n",
            "Epoch 377/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2526 - acc: 0.6515\n",
            "Epoch 378/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2561 - acc: 0.6535\n",
            "Epoch 379/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.2470 - acc: 0.6537\n",
            "Epoch 380/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2587 - acc: 0.6470\n",
            "Epoch 381/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.2326 - acc: 0.6586\n",
            "Epoch 382/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2390 - acc: 0.6543\n",
            "Epoch 383/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2277 - acc: 0.6578\n",
            "Epoch 384/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2426 - acc: 0.6565\n",
            "Epoch 385/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.2317 - acc: 0.6567\n",
            "Epoch 386/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2182 - acc: 0.6617\n",
            "Epoch 387/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.2170 - acc: 0.6589\n",
            "Epoch 388/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2287 - acc: 0.6578\n",
            "Epoch 389/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.2248 - acc: 0.6567\n",
            "Epoch 390/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2196 - acc: 0.6599\n",
            "Epoch 391/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2019 - acc: 0.6649\n",
            "Epoch 392/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.2147 - acc: 0.6581\n",
            "Epoch 393/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2147 - acc: 0.6590\n",
            "Epoch 394/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2195 - acc: 0.6593\n",
            "Epoch 395/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.2034 - acc: 0.6651\n",
            "Epoch 396/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2015 - acc: 0.6637\n",
            "Epoch 397/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1905 - acc: 0.6694\n",
            "Epoch 398/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1907 - acc: 0.6687\n",
            "Epoch 399/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1947 - acc: 0.6643\n",
            "Epoch 400/1000\n",
            "26318/26318 [==============================] - 6s 238us/sample - loss: 1.2009 - acc: 0.6651\n",
            "Epoch 401/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1936 - acc: 0.6676\n",
            "Epoch 402/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.2001 - acc: 0.6626\n",
            "Epoch 403/1000\n",
            "26318/26318 [==============================] - 6s 238us/sample - loss: 1.1759 - acc: 0.6694\n",
            "Epoch 404/1000\n",
            "26318/26318 [==============================] - 6s 247us/sample - loss: 1.1963 - acc: 0.6617\n",
            "Epoch 405/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1834 - acc: 0.6698\n",
            "Epoch 406/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1779 - acc: 0.6661\n",
            "Epoch 407/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1880 - acc: 0.6679\n",
            "Epoch 408/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1582 - acc: 0.6751\n",
            "Epoch 409/1000\n",
            "26318/26318 [==============================] - 6s 238us/sample - loss: 1.1752 - acc: 0.6693\n",
            "Epoch 410/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1648 - acc: 0.6727\n",
            "Epoch 411/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1689 - acc: 0.6725\n",
            "Epoch 412/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1528 - acc: 0.6797\n",
            "Epoch 413/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1572 - acc: 0.6745\n",
            "Epoch 414/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1558 - acc: 0.6745\n",
            "Epoch 415/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1612 - acc: 0.6738\n",
            "Epoch 416/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1649 - acc: 0.6739\n",
            "Epoch 417/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1507 - acc: 0.6761\n",
            "Epoch 418/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1559 - acc: 0.6740\n",
            "Epoch 419/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1553 - acc: 0.6707\n",
            "Epoch 420/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1355 - acc: 0.6789\n",
            "Epoch 421/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1467 - acc: 0.6766\n",
            "Epoch 422/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1416 - acc: 0.6777\n",
            "Epoch 423/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1363 - acc: 0.6797\n",
            "Epoch 424/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1197 - acc: 0.6845\n",
            "Epoch 425/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1234 - acc: 0.6835\n",
            "Epoch 426/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.1352 - acc: 0.6801\n",
            "Epoch 427/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1238 - acc: 0.6834\n",
            "Epoch 428/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 1.1270 - acc: 0.6836\n",
            "Epoch 429/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1345 - acc: 0.6811\n",
            "Epoch 430/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1499 - acc: 0.6778\n",
            "Epoch 431/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1492 - acc: 0.6754\n",
            "Epoch 432/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1365 - acc: 0.6812\n",
            "Epoch 433/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1093 - acc: 0.6835\n",
            "Epoch 434/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1177 - acc: 0.6842\n",
            "Epoch 435/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1147 - acc: 0.6819\n",
            "Epoch 436/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1103 - acc: 0.6864\n",
            "Epoch 437/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1125 - acc: 0.6846\n",
            "Epoch 438/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.1070 - acc: 0.6863\n",
            "Epoch 439/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.1047 - acc: 0.6877\n",
            "Epoch 440/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.1005 - acc: 0.6898\n",
            "Epoch 441/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.0934 - acc: 0.6914\n",
            "Epoch 442/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0958 - acc: 0.6904\n",
            "Epoch 443/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0874 - acc: 0.6899\n",
            "Epoch 444/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0848 - acc: 0.6915\n",
            "Epoch 445/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.0833 - acc: 0.6902\n",
            "Epoch 446/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0904 - acc: 0.6896\n",
            "Epoch 447/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0833 - acc: 0.6909\n",
            "Epoch 448/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0893 - acc: 0.6878\n",
            "Epoch 449/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0778 - acc: 0.6940\n",
            "Epoch 450/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0883 - acc: 0.6920\n",
            "Epoch 451/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 1.0817 - acc: 0.6957\n",
            "Epoch 452/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 1.0806 - acc: 0.6918\n",
            "Epoch 453/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 1.0730 - acc: 0.6967\n",
            "Epoch 454/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0779 - acc: 0.6895\n",
            "Epoch 455/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0771 - acc: 0.6945\n",
            "Epoch 456/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0787 - acc: 0.6940\n",
            "Epoch 457/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0705 - acc: 0.6956\n",
            "Epoch 458/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0782 - acc: 0.6910\n",
            "Epoch 459/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0625 - acc: 0.6973\n",
            "Epoch 460/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0541 - acc: 0.7001\n",
            "Epoch 461/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0567 - acc: 0.7007\n",
            "Epoch 462/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0635 - acc: 0.6952\n",
            "Epoch 463/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0528 - acc: 0.6969\n",
            "Epoch 464/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0587 - acc: 0.6942\n",
            "Epoch 465/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0387 - acc: 0.7043\n",
            "Epoch 466/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0476 - acc: 0.7031\n",
            "Epoch 467/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0684 - acc: 0.6971\n",
            "Epoch 468/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0449 - acc: 0.7009\n",
            "Epoch 469/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0519 - acc: 0.6990\n",
            "Epoch 470/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0338 - acc: 0.7028\n",
            "Epoch 471/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0255 - acc: 0.7061\n",
            "Epoch 472/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0229 - acc: 0.7088\n",
            "Epoch 473/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0303 - acc: 0.7073\n",
            "Epoch 474/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0370 - acc: 0.7015\n",
            "Epoch 475/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 1.0260 - acc: 0.7055\n",
            "Epoch 476/1000\n",
            "26318/26318 [==============================] - 6s 244us/sample - loss: 1.0298 - acc: 0.7060\n",
            "Epoch 477/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0345 - acc: 0.6998\n",
            "Epoch 478/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0331 - acc: 0.7018\n",
            "Epoch 479/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0361 - acc: 0.7039\n",
            "Epoch 480/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0308 - acc: 0.7069\n",
            "Epoch 481/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0264 - acc: 0.7055\n",
            "Epoch 482/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0251 - acc: 0.7071\n",
            "Epoch 483/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0306 - acc: 0.7033\n",
            "Epoch 484/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0295 - acc: 0.7054\n",
            "Epoch 485/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0019 - acc: 0.7135\n",
            "Epoch 486/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0156 - acc: 0.7094\n",
            "Epoch 487/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0181 - acc: 0.7083\n",
            "Epoch 488/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0296 - acc: 0.7066\n",
            "Epoch 489/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0202 - acc: 0.7075\n",
            "Epoch 490/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0122 - acc: 0.7099\n",
            "Epoch 491/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 1.0138 - acc: 0.7083\n",
            "Epoch 492/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 1.0061 - acc: 0.7091\n",
            "Epoch 493/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9923 - acc: 0.7158\n",
            "Epoch 494/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9909 - acc: 0.7155\n",
            "Epoch 495/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9925 - acc: 0.7135\n",
            "Epoch 496/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9896 - acc: 0.7164\n",
            "Epoch 497/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9887 - acc: 0.7127\n",
            "Epoch 498/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.9958 - acc: 0.7108\n",
            "Epoch 499/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9867 - acc: 0.7151\n",
            "Epoch 500/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9839 - acc: 0.7175\n",
            "Epoch 501/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9816 - acc: 0.7177\n",
            "Epoch 502/1000\n",
            "26318/26318 [==============================] - 6s 245us/sample - loss: 0.9719 - acc: 0.7194\n",
            "Epoch 503/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9923 - acc: 0.7139\n",
            "Epoch 504/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9933 - acc: 0.7111\n",
            "Epoch 505/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9875 - acc: 0.7145\n",
            "Epoch 506/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9695 - acc: 0.7225\n",
            "Epoch 507/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9646 - acc: 0.7232\n",
            "Epoch 508/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9782 - acc: 0.7159\n",
            "Epoch 509/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9732 - acc: 0.7208\n",
            "Epoch 510/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9709 - acc: 0.7196\n",
            "Epoch 511/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9708 - acc: 0.7177\n",
            "Epoch 512/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9619 - acc: 0.7230\n",
            "Epoch 513/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9742 - acc: 0.7205\n",
            "Epoch 514/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9656 - acc: 0.7241\n",
            "Epoch 515/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9666 - acc: 0.7200\n",
            "Epoch 516/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9580 - acc: 0.7215\n",
            "Epoch 517/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9579 - acc: 0.7262\n",
            "Epoch 518/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9626 - acc: 0.7236\n",
            "Epoch 519/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9645 - acc: 0.7211\n",
            "Epoch 520/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9418 - acc: 0.7292\n",
            "Epoch 521/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9434 - acc: 0.7269\n",
            "Epoch 522/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9490 - acc: 0.7263\n",
            "Epoch 523/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.9644 - acc: 0.7226\n",
            "Epoch 524/1000\n",
            "26318/26318 [==============================] - 6s 243us/sample - loss: 0.9542 - acc: 0.7224\n",
            "Epoch 525/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9443 - acc: 0.7251\n",
            "Epoch 526/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9529 - acc: 0.7254\n",
            "Epoch 527/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9506 - acc: 0.7249\n",
            "Epoch 528/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9485 - acc: 0.7260\n",
            "Epoch 529/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9414 - acc: 0.7283\n",
            "Epoch 530/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9440 - acc: 0.7242\n",
            "Epoch 531/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9457 - acc: 0.7266\n",
            "Epoch 532/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9433 - acc: 0.7274\n",
            "Epoch 533/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.9434 - acc: 0.7289\n",
            "Epoch 534/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9400 - acc: 0.7284\n",
            "Epoch 535/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.9358 - acc: 0.7300\n",
            "Epoch 536/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9374 - acc: 0.7264\n",
            "Epoch 537/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9405 - acc: 0.7273\n",
            "Epoch 538/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9322 - acc: 0.7278\n",
            "Epoch 539/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9350 - acc: 0.7281\n",
            "Epoch 540/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9372 - acc: 0.7297\n",
            "Epoch 541/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9293 - acc: 0.7290\n",
            "Epoch 542/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9227 - acc: 0.7320\n",
            "Epoch 543/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9326 - acc: 0.7277\n",
            "Epoch 544/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9377 - acc: 0.7301\n",
            "Epoch 545/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9202 - acc: 0.7331\n",
            "Epoch 546/1000\n",
            "26318/26318 [==============================] - 6s 242us/sample - loss: 0.9202 - acc: 0.7324\n",
            "Epoch 547/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9161 - acc: 0.7336\n",
            "Epoch 548/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9246 - acc: 0.7307\n",
            "Epoch 549/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9328 - acc: 0.7302\n",
            "Epoch 550/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9265 - acc: 0.7277\n",
            "Epoch 551/1000\n",
            "26318/26318 [==============================] - 6s 246us/sample - loss: 0.9280 - acc: 0.7287\n",
            "Epoch 552/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9194 - acc: 0.7324\n",
            "Epoch 553/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9197 - acc: 0.7343\n",
            "Epoch 554/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9104 - acc: 0.7336\n",
            "Epoch 555/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9236 - acc: 0.7284\n",
            "Epoch 556/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9097 - acc: 0.7360\n",
            "Epoch 557/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.9242 - acc: 0.7316\n",
            "Epoch 558/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.8989 - acc: 0.7378\n",
            "Epoch 559/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.9049 - acc: 0.7350\n",
            "Epoch 560/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9057 - acc: 0.7361\n",
            "Epoch 561/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9029 - acc: 0.7351\n",
            "Epoch 562/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.9044 - acc: 0.7377\n",
            "Epoch 563/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.8998 - acc: 0.7388\n",
            "Epoch 564/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.9065 - acc: 0.7365\n",
            "Epoch 565/1000\n",
            "26318/26318 [==============================] - 6s 240us/sample - loss: 0.8934 - acc: 0.7380\n",
            "Epoch 566/1000\n",
            "26318/26318 [==============================] - 6s 241us/sample - loss: 0.8996 - acc: 0.7392\n",
            "Epoch 567/1000\n",
            "26318/26318 [==============================] - 6s 239us/sample - loss: 0.8887 - acc: 0.7406\n",
            "Epoch 568/1000\n",
            "20096/26318 [=====================>........] - ETA: 1s - loss: 0.8832 - acc: 0.7423Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5riHuVGC4-gB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E3OvB801501U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8b6d301f-e64a-401c-b0b9-c0cc2cfd1cdb"
      },
      "cell_type": "code",
      "source": [
        "text=sequences[6]\n",
        "print(text+'\\n')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to get very tired of sitting by her sister on the bank and of having nothing to do once or twice she had peeped into the book her sister was reading but it had no pictures or conversations in it and what is the use of a book thought alice without\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bXYt5JjS62IQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate(model,tokenizer,seq_length,org_text,n_words):\n",
        "  result=list()\n",
        "  text=org_text\n",
        "  for _ in range(n_words):\n",
        "    encoded=tokenizer.texts_to_sequences([text])[0]\n",
        "    encoded=pad_sequences([encoded],maxlen=seq_length,truncating='pre')\n",
        "    y=model.predict_classes(encoded,verbose=0)\n",
        "    out_word=''\n",
        "    for word,index in tokenizer.word_index.items():\n",
        "      if index==y:\n",
        "        out_word=word\n",
        "        break\n",
        "    text +=' '+word\n",
        "    result.append(out_word)\n",
        "  return ' '.join(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pbrr2qZL9nav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generated=generate(model,tokenizer,seq_len,text,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJdC47CW9kV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c4cce6c7-0d25-4348-c001-ec1ba9d8f685"
      },
      "cell_type": "code",
      "source": [
        "print(generated)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pictures or conversation so she was considering in her own mind as well as she could for the hot day made her feel very sleepy and stupid whether the pleasure of making a daisychain would be worth the trouble of getting up and picking the daisies when suddenly a white rabbit with pink eyes ran close by her there was nothing so very remarkable in that nor did alice think it so very much out of the way to hear the rabbit say to itself oh dear oh dear i shall be late when she thought it over afterwards it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i7CNuATPGfEV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}